# -*- coding: utf-8 -*-
"""PhoBert

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17Jrk2PAXWQsNviQCL88l2Fc8JHZUyK-i
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pyvi

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import pandas as pd
import numpy as np
from string import digits
from collections import Counter
from pyvi import ViTokenizer
from gensim.models.word2vec import Word2Vec
from keras.utils import to_categorical
# %matplotlib inline

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/Colab Notebooks/my-project/LabNLP/Lab6-W2V+[LSTM, CRNN] Sentiment Analysis"

data_test = pd.read_csv("vlsp_sentiment_test.csv", sep='\t')
data_test.columns =['Class', 'Data']

import torch
from transformers import RobertaForSequenceClassification, AutoTokenizer

model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")

tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)

print(data_test)

print(type(data_test.values))

test_set = [x[1] for x in data_test.values]
print(len(test_set))

result = []
for sentence in test_set:
    input_ids = torch.tensor([tokenizer.encode(str(sentence))])
    with torch.no_grad():
      try:
        out = model(input_ids)
        print(out.logits.softmax(dim=-1).tolist())
        result.append(out.logits.softmax(dim=-1).tolist())
      except:
        print(sentence)
        print(test_set.index(sentence))
        pass

# remove index 31 in test_set
test_set.pop(361)

lister = [1,2,3,4,5]
print(max)

transform_resulter = []
neutral_tracking = []
counter = 0
for i in result:
  max_index = i[0]
  negative = max_index[0]
  positive = max_index[2]
  neutral = max_index[1]
  if neutral > negative and neutral > positive:
    max_value = -1
    neutral_tracking.append(counter)
  elif negative > positive:
    max_value = -1
  else:
    max_value = 0
  transform_resulter.append(max_value)
  counter +=1

print(neutral_tracking)

print(transform_resulter)

test_label = [x[0] for x in data_test.values]
print(test_label)

test_label.pop(361)

correct =0
counter_for_compare =0
for i,j in zip(transform_resulter, test_label):
  if i == j and counter_for_compare not in neutral_tracking:
    correct +=1
  counter_for_compare +=1
print("accuracy: ", correct/(len(test_label)-len(neutral_tracking)))

model.get_parameter

