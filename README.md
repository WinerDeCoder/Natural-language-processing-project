# Natural Language Processing Project: Sentiment Analysis using CNN, LSTM, and Combined Architectures

**Highlight:** **This my project in NLP course in my university - Ho Chi Minh University of Technology ( HCMUT ). This project explores various deep learning architectures for sentiment analysis, achieving improved performance compared to baseline models.**



## Introduction

This project fulfills the requirements for an NLP course at Ho Chi Minh University of Technology (HCMUT). The course explored various deep learning techniques for sentiment analysis, focusing on:

* **CNN-based Sentiment Analysis:** Leveraging convolutional layers to extract local features from text data for sentiment classification.
* **RNN-based Sentiment Analysis with LSTM:** Employing LSTMs to capture sequential dependencies within text sequences for improved sentiment understanding.
* **Word Embeddings with Word2Vec (CBOW):** Pre-training word embeddings using the CBOW (Continuous Bag-of-Words) model to represent words as numerical vectors.

## Requirements

### 1. Data Preprocessing

* **Dataset:** Describe the VLSP sentiment analysis datasets used and any preprocessing steps applied (e.g., cleaning, tokenization, text normalization).
* **Word Embeddings:** Explain how you utilize pre-trained Word2Vec embeddings (or other embedding techniques) to represent words numerically.

### 2. Model Architectures

**2.1. CNN-based Model:**

* Describe the architecture of your CNN model, including the number and configuration of convolutional layers, pooling layers, activation functions, and fully connected layers.
* Explain how the model extracts local features and performs sentiment classification.

**2.2. LSTM-based Model:**

* Detail the architecture of your LSTM model, specifying the number of LSTM layers, hidden units, and dropout layers (if applicable).
* Explain how the model captures sequential dependencies and classifies sentiment.

**2.3. Combined CNN-LSTM Model (Optional):**

* If you implemented a combined architecture, elaborate on its design. How do CNN and LSTM components interact within the model?

### 3. Model Training and Evaluation**

* Explain the training process, including hyperparameter tuning, optimization algorithm (e.g., Adam), loss function (e.g., cross-entropy), and training/validation split.
* Describe the metrics used to evaluate model performance (e.g., accuracy, F1-score, precision, recall).
* Compare between the methods.

### 4. Bonus Points
* Bonus points will be given if students can improve the performance of given model by modify the model's architecture



## My Work

### Code
Codes for each method is shown in coresponding folder name
**Attention: ** 
* The codes run in my Google Colab environment. If you want to use, remember to change them suitably in you enviroment
* I have 2 version for each method: One is .ipynb, other is .py

### Report
You can see my detailed report about explanations, codes, my improvements and experiments in the report **.pdf**



